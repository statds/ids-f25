## Synthetic Minority Over-sampling Technique (SMOTE)

This section was written by Hannah Levine, a junior majoring in 
Applied Data Analysis.

+ Pay attention to the sectioning levels.
+ Cite references with their bib key.
+ In examples, maximize usage of data set that the class is familiar with.
+ Could use datasets in Python packages or downloadable on the fly.
+ Test your section by `quarto render <filename.qmd>`.


### Introduction


### Imbalanced Datasets

load example dataset
Python examples can be put into `python` code chunks:

```{python}
from sklearn.datasets import make_classification
from collections import Counter
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

X, y = make_classification(
    n_samples=1000,
    n_features=10,
    n_informative=3,
    n_redundant=1,
    n_classes=2,
    weights=[0.99, 0.01],
    random_state=1234
)

print(f"Class distribution: {Counter(y)}")
```

### What is SMOTE?

Put materials on topic 2 here.

### Variants

Put matreials on topic 3 here.

###

### Conclusion

conclude, also mention advantages and disadvantages

### Further Readings

Put links to further materials.
